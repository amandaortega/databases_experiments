{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitc05b5b8a8cb5436a99cd3147d5a13f75",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_unique_df(paths):\n",
    "    df_final = pd.DataFrame()\n",
    "\n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path, encoding=\"latin\", skiprows=8, sep=';')\n",
    "        df_1 = df.groupby(['DATA (YYYY-MM-DD)'])['PRECIPITAÇÃO TOTAL. HORÁRIO (mm)', 'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO. HORARIA (mB)', 'TEMPERATURA DO AR - BULBO SECO. HORARIA (°C)', 'UMIDADE RELATIVA DO AR. HORARIA (%)'].mean()\n",
    "        df_2 = pd.DataFrame({'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)': df.groupby(['DATA (YYYY-MM-DD)'])['TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)'].max()})\n",
    "        df_new = pd.concat([df_1, df_2], axis=1)\n",
    "        df_final = pd.concat([df_final, df_new])\n",
    "    \n",
    "    df_final.rename(columns = {'PRECIPITAÇÃO TOTAL. HORÁRIO (mm)': 'rainfall_volume', 'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO. HORARIA (mB)' : 'atmospheric_pressure', 'TEMPERATURA DO AR - BULBO SECO. HORARIA (°C)' : 'dry_bulb_temperature', 'UMIDADE RELATIVA DO AR. HORARIA (%)' : 'relative_humidity', 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)' : 'maximum_temperature'}, inplace=True)\n",
    "\n",
    "    df_final[df_final < 0]  = pd.NA\n",
    "    df_final.dropna(inplace=True)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X and Y bases according to the series passed and the paramters tau (time delay), m (embedding dimension) and k (number of steps ahead to predict)\n",
    "def generate_XY(serie, tau, m, k):\n",
    "    N = serie.size\n",
    "\n",
    "    X = np.zeros((N - k - (m - 1) * tau, m))\n",
    "    Y = np.zeros(N - k - (m - 1) * tau)\n",
    "\n",
    "    for key, i in enumerate(range((m - 1) * tau, N - k)):\n",
    "        for m_ in range(m):\n",
    "            X[key, m_] = serie[i - m_ * tau]\n",
    "        Y[key] = serie[i + k]\n",
    "    \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def generate_bases(df):\n",
    "    for (columnName, columnData) in df.iteritems():\n",
    "        if not os.path.isdir(columnName):\n",
    "            os.mkdir(columnName)\n",
    "        \n",
    "        np.savetxt(columnName + '/' + columnName + '.csv', columnData.values)\n",
    "        \n",
    "        (X, Y) = generate_XY(columnData.values, 1, 3, 5)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=200, shuffle=False)    \n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        XY_train = min_max_scaler.fit_transform(np.concatenate((X_train, Y_train.reshape(-1, 1)), axis=1)) \n",
    "        XY_test = min_max_scaler.transform(np.concatenate((X_test, Y_test.reshape(-1, 1)), axis=1))\n",
    "\n",
    "        X_train = XY_train[:, :-1]\n",
    "        Y_train = XY_train[:, -1]\n",
    "        X_test = XY_test[:, :-1]\n",
    "        Y_test = XY_test[:, -1]        \n",
    "\n",
    "        np.savetxt(columnName + '/' + 'X_train.csv', X_train)\n",
    "        np.savetxt(columnName + '/' + 'Y_train.csv', Y_train)\n",
    "        np.savetxt(columnName + '/' + 'X_test.csv', X_test)\n",
    "        np.savetxt(columnName + '/' + 'Y_test.csv', Y_test)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_unique_df(['INMET_SE_MG_A521_PAMPULHA_01-01-2010_A_31-12-2010.csv', 'INMET_SE_MG_A521_PAMPULHA_01-01-2011_A_31-12-2011.csv', 'INMET_SE_MG_A521_PAMPULHA_01-01-2012_A_31-12-2012.csv', 'INMET_SE_MG_A521_PAMPULHA_01-01-2013_A_31-12-2013.csv'])\n",
    "generate_bases(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}